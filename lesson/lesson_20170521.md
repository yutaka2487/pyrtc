# はじめに
第三回リアルテックキャンプのアジェンダっぽいもの。  
今回は機械学習にフォーカスしてやってみる。メインはPandasとScikit-Learnというライブラリ。  
環境などは、第二回までに用意した Anaconda を使う。

----

# Pandas

PandasはPythonでデータの操作を行うためのライブラリ。  
DataFrameという行・列の二次元表形式のデータ構造をあつかう。  


## Pandasの基礎

前提知識。SeriesとDataFrameというデータ構造があり、それぞれどんなものかがわかっていればOK。  

* [pandasの基本操作 - Qiita](http://qiita.com/hi34/items/43c366dea18b46faf49d)



## DataFrameの作り方

たいてい、CSVやExcelやRDBMSなどから生データを読み込んで、それをDataFrameに変換する。  
そのときは、read_csv / read_excel / read_json / read_sql などが多用される。  
それ以外の方法でDataFrameを作ることはほとんどない。   
SeriesはDataFrameから切り出すことはあるが、Seriesを単独でつくることはほとんどない。  

ここで公開されている自動車のデータ（CSVとExcel）をDataFrameとして読み込んでみる。

* [2004 Cars and Trucks | Interactive Data Visualization](http://www.idvbook.com/teaching-aid/data-sets/2004-cars-and-trucks-data/)

## ブロキャス・フィルタリングの概念

ブロードキャスト演算（足りない次元は補われる）

* [Python pandas の算術演算 / 集約関数 / 統計関数まとめ - StatsFragments](http://sinhrks.hatenablog.com/entry/2014/11/27/232150)

フィルタリング（行や列を絞り込むときの考え方）

* [Pandas でデータフレームから特定の行・列を取得する – Python でデータサイエンス](http://pythondatascience.plavox.info/pandas/%E8%A1%8C%E3%83%BB%E5%88%97%E3%81%AE%E6%8A%BD%E5%87%BA)

前述の自動車のデータを使って、いろいろなブロキャス・フィルタリングをやってみる。

1. Sports Carのみに絞り込む
1. Vehicle Name列を加工してMaker列を追加する
1. CityMPG列はMPG（マイル／ガロン）が単位なのでK/L（キロメートル／リットル）に直す


## Axisの概念

まずは以下の参考サイトで、画像を最初に見て、何を言おうとしているか想像しながら解説を読むとよいかも。  
Axis=0が縦方向、Axis=1が横方向、というのがしっかりと理解できていればOK。  

* [Python pandas 図でみる データ連結 / 結合処理 - StatsFragments](http://sinhrks.hatenablog.com/entry/2015/01/28/073327)


## Groupbyオブジェクトの概念

何かでグルーピングして、グループごとに集約する方法。

* [Python pandas でのグルーピング/集約/変換処理まとめ - StatsFragments](http://sinhrks.hatenablog.com/entry/2014/10/13/005327)

前述の自動車のデータを使って、いろいろなグルーピングをやってみる。

1. Makerごとにいくつ車種があるか
2. Makerごとの平均燃費
3. Cylごとの排気量の分布（最小値・中央値・平均値・最大値）


## 複数データのマージの概念

単純な縦結合・横結合は、Axisの概念で触れたとおり。  
ここでは結合キーを指定したマージ処理、デカルト積・reft / right / outer / inner の違いを理解する。  
これらの概念はPandas以外でも常識的に使われるため、ここで覚えておくとよい。  

* [PandasでMergeする時の基礎的な振る舞い - CivilClothes](http://d.hatena.ne.jp/civilclothes/20140529/1401357962)


## チートシート

こまったらコレを見れば、とりあえず何とかなりそう。

* [ゆるふわPandasチートシート - Qiita](http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac)


----
# Scikit-Learn
## タイタニック再び

前回、Kaggleから学習用・検証用のふたつのCSVを取得して試しにモデリングしてみた。  
生存したかどうかを判別するSurvivedフラグは学習用のデータにしか存在しないが、  
誰かが全乗客の生存状況データを公開しているため、それで検証用データに対して答え合わせができる。

* [Titanic Dataset v3.5 - Google 検索](https://www.google.co.jp/search?q=Titanic+Dataset+v3.5)

で検索、DataFrameに変換する。  
名前で結合できるかと思いきや、データ加工のテクニックが必要になる！！  
Pandasの復習としてがんばりどころである。単純に名前の一致では結合できないため、工夫が必要。  

* [Python で文字列の類似度を比較する - 無駄と文化](http://blog.mudatobunka.org/entry/2016/05/08/154934)

などを参考にやってみよう。  
これができると、検証用データでの精度チェックが非常にはかどるため、がんばる。  


## 銀行の口座開設者を予測

ルールなどは以下を参考に。ちなみに片山は55/285位にランクインしている模様。  

* [コンテスト詳細 ビッグデータ活用ならオプトDSL DeepAnalytics](https://deepanalytics.jp/compe/1)

よく使うアルゴリズムとその用途などを紹介。  

```
* 要因を把握する（ルールを可視化）
  * 決定木
  
* それぞれの要因が変化したときの影響を把握する（係数を算出）
  * ロジスティック回帰

* なるべく正確に予測したい（アンサンブル系）  
  * ランダムフォレスト  
  * 勾配ブースティング  
  * AutoML系ライブラリ（auto-sklearn/tpot等）  

* 人工知能への入口（ニューラルネットワーク系）
  * 多層パーセプトロン
  * DeepLearning系ライブラリ（kears等）
```

  各自、好きなアルゴリズムを選んでモデリングしてみる。  
  Pandasによるデータ加工も必要なのでがんばる。  


----
# モデリング事例

時間があったら、コードと資料ベースで事例紹介。
