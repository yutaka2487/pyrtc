# はじめに
第三回リアルテックキャンプのアジェンダっぽいもの。  
今回は機械学習にフォーカスしてやってみる。メインはPandasとScikit-Learnというライブラリ。  
環境などは、第二回までに用意した Anaconda を使う。

----
# 参考書籍
本キャンプでの講義内容は、全て以下の書籍にまとまっている。  
このため、きちんと網羅的・体系的に学習したいのであれば、以下を購入することをすすめる。

* [Pythonによるデータ分析入門 ―NumPy、pandasを使ったデータ処理](https://www.amazon.co.jp/Python%E3%81%AB%E3%82%88%E3%82%8B%E3%83%87%E3%83%BC%E3%82%BF%E5%88%86%E6%9E%90%E5%85%A5%E9%96%80-_NumPy%E3%80%81pandas%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%9F%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-Wes-McKinney/dp/4873116554/ref=pd_sim_14_3?_encoding=UTF8&psc=1&refRID=VFAQK96FBVKAA1PA7G3D)
* [Python機械学習プログラミング 達人データサイエンティストによる理論と実践 (impress top gear)](https://www.amazon.co.jp/Python%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0-%E9%81%94%E4%BA%BA%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%83%86%E3%82%A3%E3%82%B9%E3%83%88%E3%81%AB%E3%82%88%E3%82%8B%E7%90%86%E8%AB%96%E3%81%A8%E5%AE%9F%E8%B7%B5-impress-top-gear/dp/4844380605)


----
# Pandas

PandasはPythonでデータの操作を行うためのライブラリ。  
DataFrameという行・列の二次元表形式のデータ構造をあつかう。  


## Pandasの基礎

前提知識。SeriesとDataFrameというデータ構造があり、それぞれどんなものかがわかっていればOK。  

* [pandasの基本操作 - Qiita](http://qiita.com/hi34/items/43c366dea18b46faf49d)



## DataFrameの作り方

たいてい、CSVやExcelやRDBMSなどから生データを読み込んで、それをDataFrameに変換する。  
そのときは、read_csv / read_excel / read_json / read_sql などが多用される。  
それ以外の方法でDataFrameを作ることはほとんどない。   
SeriesはDataFrameから切り出すことはあるが、Seriesを単独でつくることはほとんどない。  

ここで公開されている自動車のデータ（CSVとExcel）をDataFrameとして読み込んでみる。

* [2004 Cars and Trucks | Interactive Data Visualization](http://www.idvbook.com/teaching-aid/data-sets/2004-cars-and-trucks-data/)

## ブロキャス・フィルタリングの概念

ブロードキャスト演算（足りない次元は補われる）

* [Python pandas の算術演算 / 集約関数 / 統計関数まとめ - StatsFragments](http://sinhrks.hatenablog.com/entry/2014/11/27/232150)

フィルタリング（行や列を絞り込むときの考え方）

* [Pandas でデータフレームから特定の行・列を取得する – Python でデータサイエンス](http://pythondatascience.plavox.info/pandas/%E8%A1%8C%E3%83%BB%E5%88%97%E3%81%AE%E6%8A%BD%E5%87%BA)

前述の自動車のデータを使って、いろいろなブロキャス・フィルタリングをやってみる。

1. Sports Carのみに絞り込む
1. Vehicle Name列を加工してMaker列を追加する
1. CityMPG列はMPG（マイル／ガロン）が単位なのでK/L（キロメートル／リットル）に直す

![image](https://cloud.githubusercontent.com/assets/16130358/26242756/7eba8214-3cc4-11e7-820c-109f549622fe.png)


## Axisの概念

まずは以下の参考サイトで、画像を最初に見て、何を言おうとしているか想像しながら解説を読むとよいかも。  
Axis=0が縦方向、Axis=1が横方向、というのがしっかりと理解できていればOK。  

* [Python pandas 図でみる データ連結 / 結合処理 - StatsFragments](http://sinhrks.hatenablog.com/entry/2015/01/28/073327)

[![LGTM](http://i.stack.imgur.com/DL0iQ.jpg)](http://i.stack.imgur.com/DL0iQ.jpg)

## Groupbyオブジェクトの概念

何かでグルーピングして、グループごとに集約する方法。

* [Python pandas でのグルーピング/集約/変換処理まとめ - StatsFragments](http://sinhrks.hatenablog.com/entry/2014/10/13/005327)

前述の自動車のデータを使って、いろいろなグルーピングをやってみる。

1. Makerごとにいくつ車種があるか
2. Makerごとの平均燃費
3. Cylごとの排気量の分布（最小値・中央値・平均値・最大値）

![image](https://cloud.githubusercontent.com/assets/16130358/26243238/1c8b4536-3cc6-11e7-8632-a60d06f38145.png)


## 複数データのマージの概念

単純な縦結合・横結合は、Axisの概念で触れたとおり。  
ここでは結合キーを指定したマージ処理、デカルト積・reft / right / outer / inner の違いを理解する。  
これらの概念はPandas以外でも常識的に使われるため、ここで覚えておくとよい。  

* [PandasでMergeする時の基礎的な振る舞い - CivilClothes](http://d.hatena.ne.jp/civilclothes/20140529/1401357962)


## チートシート

こまったらコレを見れば、とりあえず何とかなりそう。

* [ゆるふわPandasチートシート - Qiita](http://qiita.com/tanemaki/items/2ed05e258ef4c9e6caac)


----
# Scikit-Learn
## タイタニック再び

前回、Kaggleから学習用・検証用のふたつのCSVを取得して試しにモデリングしてみた。  
生存したかどうかを判別するSurvivedフラグは学習用のデータにしか存在しないが、  
誰かが全乗客の生存状況データを公開しているため、それで検証用データに対して答え合わせができる。

* [Titanic Dataset v3.5 - Google 検索](https://www.google.co.jp/search?q=Titanic+Dataset+v3.5)

で検索、DataFrameに変換する。  
Kaggleの検証データと名前で結合できるかと思いきや、データ加工のテクニックが必要になる！！  
Pandasの復習としてがんばりどころである。  

* [Python で文字列の類似度を比較する - 無駄と文化](http://blog.mudatobunka.org/entry/2016/05/08/154934)

などを参考にやってみよう。  
これができると、検証用データでの精度チェックが非常にはかどるため、がんばる。  
以下、ちょっとだけ名前が違っているため、単純に結合できないデータを無理やり結合した例。   

![image](https://cloud.githubusercontent.com/assets/16130358/26246046/1aa15a1a-3cd2-11e7-8e1a-34afd695ba51.png)


## 銀行の口座開設者を予測

ルールなどは以下を参考に。ちなみに片山は55/285位にランクインしている模様。  

* [コンテスト詳細 ビッグデータ活用ならオプトDSL DeepAnalytics](https://deepanalytics.jp/compe/1)

よく使うアルゴリズムとその用途などを紹介。  

```
* 要因を把握する（ルールを可視化）
  * 決定木
  
* それぞれの要因が変化したときの影響を把握する（係数を算出）
  * ロジスティック回帰

* なるべく正確に予測したい（アンサンブル系）  
  * ランダムフォレスト  
  * 勾配ブースティング  
  * AutoML系ライブラリ（auto-sklearn/tpot等）  

* 人工知能への入口（ニューラルネットワーク系）
  * 多層パーセプトロン
  * DeepLearning系ライブラリ（kears等）
```

  各自、好きなアルゴリズムを選んでモデリングしてみる。  
  Pandasによるデータ加工も必要なのでがんばる。  


----
# モデリング事例

時間があったら、コードと資料ベースで事例紹介。
